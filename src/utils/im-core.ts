// IM-CORE 1.074
// NOTE: I'm currently working on 3 different apps with this framework,
// so even though I thought it was mostly finished, the API appears to still be changing slightly.
// Majority of the last changes have just been updates to the documentation though

import { assert } from "src/utils/assert";

// Conventions
//  - An 'immediate mode' method or 'im' method is any method that eventually _writes_ to the `ImCache`.
//    These methods should ideally be prefixed with 'im'.
//    Conversely, methods that don't touch the imCache, or that will only ever _read_ from the imCache, should NOT be prefixed with 'im'.
//    This allows developers (and in the future, static analysis tools) to know that this method can't be rendered conditionally, or
//    out of order, similar to how React hooks work. This is really the only convention I would recommend you actually follow.
//
//  - imMethods that begin a scope and have a corresponding method to end that scope should be called `im<Name>Begin` and `im<Name>End`. 
//    Some day, I plan on making an eslint rule that will make use of this convention to flag missing closing statements.
//    Though I have significantly reduced the chance of this bug happening with typeIds and such,
//    missing begin/end statements not being paired corectly can still not be caught, and it can 
//    cause some strange behaviour or even silent data corruption in some cases.
//
//    NOTE: This framework still may have methods or utils that I called them so frequently that I omitted the `Begin` from them. 
//    As discussed above, I'm in the process of renaming them to conform to `<Begin>/<End>`. There will be carve-outs for
//    imIf, imSwitch, imFor and other basic control-flow stuff. I should probably just make this 
//    static analysis tool - it would speed up the process...


export const ENTRIES_IDX                             = 0;
export const ENTRIES_LAST_IDX                        = 1;
export const ENTRIES_INTERNAL_TYPE                   = 2;
export const ENTRIES_PARENT_TYPE                     = 3;
export const ENTRIES_PARENT_VALUE                    = 4;
export const ENTRIES_COMPLETED_ONE_RENDER            = 5;
export const ENTRIES_KEYED_MAP                       = 6;
export const ENTRIES_REMOVE_LEVEL                    = 7;
export const ENTRIES_IS_IN_CONDITIONAL_PATHWAY       = 8;
export const ENTRIES_IS_DERIVED                      = 9;
export const ENTRIES_STARTED_CONDITIONALLY_RENDERING = 10;
export const ENTRIES_DESTRUCTORS                     = 11;
export const ENTRIES_KEYED_MAP_REMOVE_LEVEL          = 12;
export const ENTRIES_ITEMS_START                     = 13;

/**
 * Allows us to cache state for our immediate mode callsites.
 * Initialize this on your end with `const cache: ImCache = [];`. It's just an array
 */
export type ImCache = (ImCacheEntries | any)[]; 
export type ImCacheEntries = any[] & { __ImCacheEntries: void };

export type FpsCounterState = {
    renderCount: number;
    lastRenderCount: number;
    renderStart: number;
    renderEnd: number;
    frameMs: number;
    renderMs: number;
}

export function newFpsCounterState(): FpsCounterState {
    return {
        renderCount: 0,
        lastRenderCount: 0,
        renderStart: 0,
        renderEnd: 0,
        frameMs: 0,
        renderMs: 0,
    }
}

export function fpsMarkRenderingStart(fps: FpsCounterState) {
    const t = performance.now();;

    fps.renderMs = fps.renderEnd - fps.renderStart;
    fps.frameMs = t - fps.renderStart;
    fps.renderStart = t;
    fps.lastRenderCount = fps.renderCount;
    fps.renderCount = 0;
}

export function fpsMarkRenderingEnd(fps: FpsCounterState) {
    fps.renderEnd = performance.now();
}


export const CACHE_IDX                          = 0;
export const CACHE_CURRENT_ENTRIES              = 1;
export const CACHE_CURRENT_WAITING_FOR_SET      = 2;
export const CACHE_FPS_COUNTER_STATE            = 3; // Useful for debugging performance in general, and running expensive computations over multiple frames
export const CACHE_CONTEXTS                     = 4;
export const CACHE_ROOT_ENTRIES                 = 5;
export const CACHE_NEEDS_RERENDER               = 6;
export const CACHE_RERENDER_FN                  = 7;
export const CACHE_RERENDER_FN_INNER            = 8;
export const CACHE_SELF_REFERENCE               = 9;
export const CACHE_IS_RENDERING                 = 10;
export const CACHE_IS_EVENT_RERENDER            = 11;
export const CACHE_RENDER_COUNT                 = 12;
export const CACHE_ANIMATE_FN                   = 13;
export const CACHE_ANIMATION_ID                 = 14;
export const CACHE_ANIMATION_TIME_LAST          = 15;
export const CACHE_ANIMATION_TIME               = 16;
export const CACHE_ANIMATION_DELTA_TIME_SECONDS = 17;
export const CACHE_ITEMS_ITERATED               = 18;
export const CACHE_ITEMS_ITERATED_LAST_FRAME    = 19; // Useful performance metric
export const CACHE_TOTAL_DESTRUCTORS            = 20; // Useful memory leak indicator
export const CACHE_TOTAL_MAP_ENTRIES            = 21; // Useful memory leak indicator
export const CACHE_TOTAL_MAP_ENTRIES_LAST_FRAME = 22; // Useful memory leak indicator
export const CACHE_HMR_ENABLED                  = 23;  // TODO: Delete HMR - we'll come back and try this again later
export const CACHE_HMR_STATE_INCOMPATIBLE       = 24;
export const CACHE_RENDER_FN_CHANGES            = 25;
export const CACHE_ENTRIES_START                = 26;


export const REMOVE_LEVEL_NONE = 1;
// This is the default remove level for im-blocks, im-arrays, im-if/else conditionals, and im-switch.
// The increase in performance far oughtweighs any memory problems.
export const REMOVE_LEVEL_DETATCHED = 2;
// This is the default for im-keyed map entries. This is because we can key components on arbitrary values. 
// It is common (and intended behaviour) to use object references directly as keys.
// However, if those objects are constantly created and destroyed, this can pose a problem for REMOVE_LEVEL_DETATCHED. 
// Using REMOVE_LEVEL_DESTROYED instead allows the map to clean up and remove those keys, so 
// that the size of the map isn't constantly increasing.
export const REMOVE_LEVEL_DESTROYED = 3;

export type RemovedLevel
    = typeof REMOVE_LEVEL_NONE
    | typeof REMOVE_LEVEL_DETATCHED   
    | typeof REMOVE_LEVEL_DESTROYED;

// TypeIDs allow us to provide some basic sanity checks and protection
// against the possiblity of data corruption that can happen when im-state is accessed 
// conditionally or out of order. The idea is that rather than asking you to pass in 
// some random number, or to save a bunch of type ID integers everywhere, you can 
// just pass in a reference to a function to uniquely identify a piece of state.
// You probably have a whole bunch of them lying around somewhere.
// The function that you are creating the state from, for example. 
// The return value of the function can be used to infer the return value of
// the {@link imGetsState} call, but it can also be a completely unrelated function
// - in which case you can just use {@link imInlineTypeId}. As long as a function
// has been uniquely used within a particular entry list at a particular slot, the 
// likelyhood of out-of-order rendering errors will reduce to almost 0.
export type TypeId<T> = (...args: any[]) => T;

/**
 * Used when the return type of the typeId function has nothing to do with the contents of the state.
 * We still need some way to check for out-of-order rendering bugs, and you probably have a function or two nearby that you can use.
 * This is an alterantive to the prior implementation, which forced you to pollute your module scopes with named integers.
 *
 * ```ts
 * let pingPong; pingPong = imGet(c, inlineTypeId(Math.sin));
 * if (!pingPong) pingPong = imSet(c, { t: 0 });
 * ```
 */
export function inlineTypeId<T = undefined>(fn: Function) {
    return fn as TypeId<T>;
}

// Can be any valid object reference. Or string, but avoid string if you can - string comparisons are slower than object comparisons
export type ValidKey = string | number | Function | object | boolean | null | unknown;

export const USE_MANUAL_RERENDERING = 1 << 0;
export const USE_REQUEST_ANIMATION_FRAME = 1 << 1;

/**
 * Pass in {@link USE_REQUEST_ANIMATION_FRAME} to get the intended experience - 
 * The animatin loop will make the following things significantly easier:
 *  - Animating that one thing
 *  - Writing robust javascript interaction logic that doesn't keep getting stuck in a particular bugged 
 *      state due to callbacks not being fired when you thought they would
 *  - 'reacting' to any state from anywhere. VanillaJS objects, your own data stores, api responses, you name it
 *
 * If you want to avoid the animation loop for whatever reason, pass in the {@link USE_MANUAL_RERENDERING} flag instead.
 *  - You'll need to manually call c[CACHE_RERENDER_FN]() whenever any state anywhere changes.
 *  - Methods that previously reported a deltaTime will report a constant 1/30 instead.
 * 
 * NOTE: the rerender function and the `useEventLoop` parameter are completely ignored after the first render, and this will never change.
 */
export function imCacheBegin(
    c: ImCache,
    renderFn: (c: ImCache) => void,
    flags: typeof USE_REQUEST_ANIMATION_FRAME | typeof USE_MANUAL_RERENDERING,
) {
    if (c.length === 0) {
        c.length = CACHE_ENTRIES_START;
        c.fill(undefined);

        // starts at -1 and increments onto the current value. So we can keep accessing this idx over and over without doing idx - 1.
        // NOTE: memory access is supposedly far slower than math. So might not matter too much
        c[CACHE_IDX] = 0;
        c[CACHE_CONTEXTS] = [];
        c[CACHE_ROOT_ENTRIES] = [];
        c[CACHE_CURRENT_ENTRIES] = c[CACHE_ROOT_ENTRIES];
        c[CACHE_CURRENT_WAITING_FOR_SET] = false;
        c[CACHE_NEEDS_RERENDER] = false;
        c[CACHE_ITEMS_ITERATED] = 0;
        c[CACHE_ITEMS_ITERATED_LAST_FRAME] = 0;
        c[CACHE_TOTAL_DESTRUCTORS] = 0;
        c[CACHE_TOTAL_MAP_ENTRIES] = 0;
        c[CACHE_TOTAL_MAP_ENTRIES_LAST_FRAME] = 0;
        c[CACHE_IS_RENDERING] = true; 
        c[CACHE_RENDER_COUNT] = 0;
        c[CACHE_FPS_COUNTER_STATE] = newFpsCounterState();

        c[CACHE_SELF_REFERENCE] = c;

        // Deltatime should naturally reach 0 on 'rerenders'. Not sure how it will work for manual rendering.
        c[CACHE_ANIMATION_TIME] = 0;
        c[CACHE_ANIMATION_TIME_LAST] = 0;

        if ((flags & USE_MANUAL_RERENDERING) !== 0) {
            // Nothing - for now
        } else if ((flags & USE_REQUEST_ANIMATION_FRAME) !== 0) {
            c[CACHE_ANIMATION_DELTA_TIME_SECONDS] = 0;
            c[CACHE_ANIMATION_ID] = 0;
        } else {
            throw new Error("Invalid flags");
        }

        c[CACHE_HMR_ENABLED]            = false;
        c[CACHE_HMR_STATE_INCOMPATIBLE] = false;
        c[CACHE_RENDER_FN_CHANGES]      = 0;
    }

    if (c[CACHE_RERENDER_FN_INNER] !== renderFn) {
        c[CACHE_RERENDER_FN_INNER] = renderFn;

        // In a production app, this should remain 1.
        // In a dev environment with HMR enabled, it should be incrementing each
        // time HMR causes the render function to reload.
        const id = c[CACHE_RENDER_FN_CHANGES] + 1;
        c[CACHE_RENDER_FN_CHANGES] = id;

        cancelAnimationFrame(c[CACHE_ANIMATION_ID]);

        c[CACHE_RERENDER_FN] = (c: ImCache) => {
            // I've found a significant speedup by writing code like
            // if (x === false) or if (x === true) instaed of if (!x) or if (x).
            // You won't need to do this in 99.9999% of your code, but it
            // would be nice if all 'library'-like code that underpins most of the stuff did it.
            if (c[CACHE_IS_RENDERING] === true) {
                // we can't rerender right here, so we'll queue a rerender at the end of the component
                c[CACHE_NEEDS_RERENDER] = true;
            } else {
                c[CACHE_IS_EVENT_RERENDER] = true;
                try {
                    renderFn(c);
                } catch (e) {
                    console.error(e);
                }
                c[CACHE_IS_EVENT_RERENDER] = false;
            }
        };


        if ((flags & USE_MANUAL_RERENDERING) !== 0) {
            c[CACHE_ANIMATE_FN]   = noOp;
            c[CACHE_ANIMATION_ID] = null;
        } else if ((flags & USE_REQUEST_ANIMATION_FRAME) !== 0) {
            const animateFn = (t: number) => {
                if (c[CACHE_IS_RENDERING] === true) {
                    // This will make debugging a lot easier. Otherwise the animation will play while
                    // we're breakpointed. Firefox moment. xD
                    return;
                }

                if (c[CACHE_RERENDER_FN_INNER] !== renderFn) {
                    return;
                }

                c[CACHE_ANIMATION_TIME] = t;

                renderFn(c);

                // we actually _want_ this to go stale
                requestAnimationFrame(animateFn);
            }
            c[CACHE_ANIMATE_FN]   = animateFn;
            c[CACHE_ANIMATION_ID] = requestAnimationFrame(animateFn);
        } else {
            throw new Error("Invalid flags");
        }
    }

    const fpsState = getFpsCounterState(c);
    if (c[CACHE_IS_EVENT_RERENDER] === false) {
        fpsMarkRenderingStart(fpsState);
    }
    fpsState.renderCount += 1;

    c[CACHE_NEEDS_RERENDER] = false;
    c[CACHE_IS_RENDERING] = true; 
    c[CACHE_IDX] = CACHE_ENTRIES_START - 1;
    c[CACHE_ITEMS_ITERATED_LAST_FRAME] = c[CACHE_ITEMS_ITERATED];
    c[CACHE_ITEMS_ITERATED] = 0;
    c[CACHE_TOTAL_MAP_ENTRIES_LAST_FRAME] = c[CACHE_TOTAL_MAP_ENTRIES];
    c[CACHE_TOTAL_MAP_ENTRIES] = 0;
    c[CACHE_CURRENT_WAITING_FOR_SET] = false;
    c[CACHE_RENDER_COUNT]++;

    if ((flags & USE_REQUEST_ANIMATION_FRAME) !== 0) {
        c[CACHE_ANIMATION_DELTA_TIME_SECONDS] = (c[CACHE_ANIMATION_TIME] - c[CACHE_ANIMATION_TIME_LAST]) / 1000;
        c[CACHE_ANIMATION_TIME_LAST] = c[CACHE_ANIMATION_TIME];
    } else {
        c[CACHE_ANIMATION_DELTA_TIME_SECONDS] = 1 / 30;
    }

    imCacheEntriesBegin(c, c[CACHE_ROOT_ENTRIES], imCacheBegin, c, INTERNAL_TYPE_CACHE);

    return c;
}

export function getFpsCounterState(c: ImCache): FpsCounterState {
    assert(c[CACHE_FPS_COUNTER_STATE] != null);
    return c[CACHE_FPS_COUNTER_STATE];
}

// Enqueues a cache rerender. 
// Usually to process an event without waiting for the next animation frame
export function rerenderImCache(c: ImCache) {
    c[CACHE_RERENDER_FN](c[CACHE_SELF_REFERENCE]);
}

function noOp() {}

export function imCacheEnd(c: ImCache) {
    imCacheEntriesEnd(c);

    const startIdx = CACHE_ENTRIES_START - 1;
    if (c[CACHE_IDX] > startIdx) {
        console.error("You've forgotten to pop some things: ", c.slice(startIdx + 1));
        throw new Error("You've forgotten to pop some things");
    } else if (c[CACHE_IDX] < startIdx) {
        throw new Error("You've popped too many thigns off the stack!!!!");
    }

    c[CACHE_IS_RENDERING] = false;

    const needsRerender = c[CACHE_NEEDS_RERENDER];
    if (needsRerender === true) {
        // Other things need to rerender the cache long after we've done a render. Mainly, DOM UI events - 
        // once we get the event, we trigger a full rerender, and pull the event out of state and use it's result in the process.
        rerenderImCache(c);

        // Some things may occur while we're rendering the framework that require is to immediately rerender
        // our components to not have a stale UI. Those events will set this flag to true, so that
        // We can eventually reach here, and do a full rerender.
        c[CACHE_NEEDS_RERENDER] = false;
    }

    if (c[CACHE_IS_EVENT_RERENDER] === false) {
        fpsMarkRenderingEnd(c[CACHE_FPS_COUNTER_STATE]);
    }
}

export function imCacheStopImmediately(c: ImCache) {
    cancelAnimationFrame(c[CACHE_ANIMATION_ID]);
    c[CACHE_RERENDER_FN] = noOp;
}

const INTERNAL_TYPE_NORMAL_BLOCK = 1;
const INTERNAL_TYPE_CONDITIONAL_BLOCK = 2;
const INTERNAL_TYPE_ARRAY_BLOCK = 3;
const INTERNAL_TYPE_KEYED_BLOCK = 4;
const INTERNAL_TYPE_TRY_BLOCK = 5;
const INTERNAL_TYPE_CACHE = 6;
const INTERNAL_TYPE_SWITCH_BLOCK = 7;

// Some common errors will get their own dedicated throw Error insead of a simple assert + comment
function internalTypeToString(internalType: number): string {
    switch (internalType) {
        case INTERNAL_TYPE_NORMAL_BLOCK:      return "INTERNAL_TYPE_NORMAL_BLOCK";
        case INTERNAL_TYPE_CONDITIONAL_BLOCK: return "INTERNAL_TYPE_CONDITIONAL_BLOCK";
        case INTERNAL_TYPE_ARRAY_BLOCK:       return "INTERNAL_TYPE_ARRAY_BLOCK";
        case INTERNAL_TYPE_KEYED_BLOCK:       return "INTERNAL_TYPE_KEYED_BLOCK";
        case INTERNAL_TYPE_TRY_BLOCK:         return "INTERNAL_TYPE_TRY_BLOCK";
        case INTERNAL_TYPE_CACHE:             return "INTERNAL_TYPE_CACHE";
        case INTERNAL_TYPE_SWITCH_BLOCK:      return "INTERNAL_TYPE_SWITCH_BLOCK";
    }

    return "Custom user type: " + internalType
}

export function imCacheEntriesBegin<T>(
    c: ImCache,
    entries: ImCacheEntries,
    parentTypeId: TypeId<T>,
    parent: T,
    internalType: number,
) {
    __imPush(c, entries);

    if (entries.length === 0) {
        for (let i = 0; i < ENTRIES_ITEMS_START; i++) {
            entries.push(undefined);
        }

        entries[ENTRIES_IDX] = ENTRIES_ITEMS_START - 2;
        entries[ENTRIES_LAST_IDX] = ENTRIES_ITEMS_START - 2;
        entries[ENTRIES_REMOVE_LEVEL] = REMOVE_LEVEL_DETATCHED;
        entries[ENTRIES_IS_IN_CONDITIONAL_PATHWAY] = false;
        entries[ENTRIES_IS_DERIVED] = false;
        entries[ENTRIES_STARTED_CONDITIONALLY_RENDERING] = false;
        entries[ENTRIES_PARENT_TYPE] = parentTypeId;
        entries[ENTRIES_INTERNAL_TYPE] = internalType;
        entries[ENTRIES_COMPLETED_ONE_RENDER] = false;
        entries[ENTRIES_PARENT_VALUE] = parent;
        entries[ENTRIES_KEYED_MAP_REMOVE_LEVEL] = REMOVE_LEVEL_DESTROYED;
    } else {
        assert(entries[ENTRIES_PARENT_TYPE] === parentTypeId);
        // NOTE: your API doesn't need to support changing this value every frame.
        // In fact, most of the APIs I have made so far don't.
        // This line of code only exists for the few times when you do want this.
        entries[ENTRIES_PARENT_VALUE] = parent;
    }

    entries[ENTRIES_IDX] = ENTRIES_ITEMS_START - 2;

    const map = entries[ENTRIES_KEYED_MAP] as (Map<ValidKey, ListMapBlock> | undefined);
    if (map !== undefined) {
        // TODO: maintain a list of things we rendered last frame.
        // This map may become massive depending on how caching has been configured.
        for (const v of map.values()) {
            v.rendered = false;
        }
    }
}

function __imPush(c: ImCache, entries: ImCacheEntries) {
    const idx = ++c[CACHE_IDX];
    if (idx === c.length) {
        c.push(entries);
    } else {
        c[idx] = entries;
    }

    c[CACHE_CURRENT_ENTRIES] = entries;
}

export function imCacheEntriesEnd(c: ImCache) {
    __imPop(c);
}

function __imPop(c: ImCache): ImCacheEntries {
    const entries = c[CACHE_CURRENT_ENTRIES];
    const idx = --c[CACHE_IDX];
    c[CACHE_CURRENT_ENTRIES] = c[idx];
    assert(idx >= CACHE_ENTRIES_START - 1);
    return entries;
}


/**
 * Allows you to get/set state inline without using lambdas, when used with {@link imSet}:
 * ```ts
 * const s = imGet(c, fn) ?? imSet(c, { blah });
 * ```
 *
 * {@link typeId} is a function reference that we use to check that susbequent state access is for the 
 * correct state. This is required, because state is indexed by the position where `imGet` is called,
 * and conditional rendering/etc can easily break this order. I've not looked at React sourcecode, but
 * I imagine it is very similar to the rule of hooks that they have.
 *
 * The type of the value is assumed to have the return type of the `typeId` function that was specified.
 * It does not necessarily need to actually be constructed by that function. 
 * See {@link imGetInline} - it does not make this assumption, and allows you to use typeIds
 * purely as an ID.
 *
 * You might need to refresh the state more often:
 *
 * ```ts
 * const depChanged = imMemo(c, dep);
 *
 * let s = imGet(c, fn);
 * if (!s || depChanged) {
 *      s = imSet(c, someConstructorFn(dep));
 * };
 * ```
 *
 * All calls to `imGet` must be followed by `imSet` the very first time, to populate the initial state.
 * An assertion will throw if this is not the case.
 * NOTE: This function is a fundamental primitive that most of the other methods in this framework are built with.
 */
export function imGet<T>(
    c: ImCache,
    typeId: TypeId<T>,
    initialValue: T | undefined = undefined
): T | undefined {
    const entries = c[CACHE_CURRENT_ENTRIES];
    c[CACHE_ITEMS_ITERATED]++;

    // Make sure you called imSet for the previous state before calling imGet again.
    assert(c[CACHE_CURRENT_WAITING_FOR_SET] === false);

    // [type, value][type,value],[typ....
    // ^----------->^
    entries[ENTRIES_IDX] += 2;

    const idx = entries[ENTRIES_IDX];
    if (idx === ENTRIES_ITEMS_START) {
        // Rendering 0 items is the signal to remove an immediate-mode block from the conditional pathway.
        // This means we can't know that an immediate mode block has re-entered the conditional pathway untill 
        // it has started rendering the first item, which is what this if-block is handling

        if (entries[ENTRIES_IS_IN_CONDITIONAL_PATHWAY] === false) {
            entries[ENTRIES_IS_IN_CONDITIONAL_PATHWAY] = true;
            entries[ENTRIES_STARTED_CONDITIONALLY_RENDERING] = true;
            entries[ENTRIES_REMOVE_LEVEL] = REMOVE_LEVEL_NONE;
        } else {
            // NOTE: if an error occured in the previous render, then
            // subsequent things that depended on `startedConditionallyRendering` being true won't run.
            // I think this is better than re-running all the things that ran successfully over and over again.
            entries[ENTRIES_STARTED_CONDITIONALLY_RENDERING] = false;
        }
    }

    if (idx < entries.length) {
        if (entries[idx] !== typeId) {
            let isError = true;
            if (c[CACHE_HMR_ENABLED] === true) {
                // During HMR, all function references get replaced. 
                // Instead of throwing, we can try comparing thier names instead:
                if (entries[idx].name !== undefined && entries[idx].name === typeId.name) {
                    console.log("[imjs] patching typeId " + typeId.name);
                    entries[idx] = typeId;
                    isError = false;
                }
            }

            if (isError) {
                c[CACHE_HMR_STATE_INCOMPATIBLE] = true;
                const errorMessage = "Expected to populate this cache entry with a different type. Your begin/end pairs probably aren't lining up right";
                console.error(errorMessage, entries[idx], typeId);
                throw new Error(errorMessage);
            }
        }
    } else if (idx === entries.length) {
        entries.push(typeId);
        entries.push(initialValue);
        c[CACHE_CURRENT_WAITING_FOR_SET] = true;
    } else {
        throw new Error("Shouldn't reach here");
    }

    return entries[idx + 1];
}

/**
 * When you have code like this:
 * ```ts
 * if (!imGet(c) || valueChanged) imSet(c, value);
 * ```
 * When value could be undefined, it will trigger every frame. You can use imSetRequired instead.
 * This code will check "allocated or nah" instead of "is the value we have undefined?", which is more correct.
 * ```ts
 * if (imSetRequired(c) || valueChanged) imSet(c, value);
 * ```
 */
export function imSetRequired(c: ImCache): boolean {
    return c[CACHE_CURRENT_WAITING_FOR_SET];
}

/**
 * Allows you to get/set state inline. Unlike {@link imGet},
 * the type returned by {@link typeIdInline} is not necessarily
 * the type being stored.
 *
 * ```ts
 * const = imGetInline(c, fn) ?? imSet(c, { blah });
 * ```
 */
export function imGetInline(
    c: ImCache,
    typeIdInline: TypeId<unknown>,
): undefined {
    // NOTE: undefined return type is a lie! Will also return whatever you set with imSet.
    // But we want typescript to infer the value of `x = imGet(c) ?? imSet(c, val)` to always be the type of val.
    return imGet(c, inlineTypeId(typeIdInline));
}


/**
 * A shorthand for a pattern that is very common.
 * NOTE: if your state gains dependencies, you can just use imGet and imSet directly, as intended.
 */
export function imState<T>(c: ImCache, fn: () => T): T {
    let val = imGet(c, fn);
    if (val === undefined) val = imSet(c, fn());
    return val;
}

export function getEntryAt<T>(c: ImCache, typeId: TypeId<T>, idx: number): T {
    const entries = c[CACHE_CURRENT_ENTRIES];
    const type = entries.at(ENTRIES_ITEMS_START + idx);
    if (type !== typeId) {
        throw new Error("Didn't find <typeId::" + typeId.name + "> at " + idx);
    }

    const val = entries[ENTRIES_ITEMS_START + idx + 1];
    return val as T;
}


export function getEntriesParent<T>(c: ImCache, typeId: TypeId<T>): T {
    // If this assertion fails, then you may have forgotten to pop some things you've pushed onto the stack
    const entries = c[CACHE_CURRENT_ENTRIES];
    assert(entries[ENTRIES_PARENT_TYPE] === typeId);
    return entries[ENTRIES_PARENT_VALUE] as T;
}

export function getEntriesParentFromEntries<T>(entries: ImCacheEntries, typeId: TypeId<T>): T | undefined {
    if (entries[ENTRIES_PARENT_TYPE] === typeId) {
        return entries[ENTRIES_PARENT_VALUE] as T;
    }
    return undefined;
}


export function imSet<T>(c: ImCache, val: T): T {
    const entries = c[CACHE_CURRENT_ENTRIES];
    const idx = entries[ENTRIES_IDX];
    entries[idx + 1] = val;
    c[CACHE_CURRENT_WAITING_FOR_SET] = false;
    return val;
}

export type ListMapBlock = { rendered: boolean; entries: ImCacheEntries; };

/**
 * Creates an entry in the _Parent's_ keyed elements map.
 */
function __imBlockKeyedBegin(c: ImCache, key: ValidKey, removeLevel: RemovedLevel) {
    const entries = c[CACHE_CURRENT_ENTRIES];
    entries[ENTRIES_KEYED_MAP_REMOVE_LEVEL] = removeLevel;

    let map = entries[ENTRIES_KEYED_MAP] as (Map<ValidKey, ListMapBlock> | undefined);
    if (map === undefined) {
        map = new Map<ValidKey, ListMapBlock>();
        entries[ENTRIES_KEYED_MAP] = map;
    }

    let block = map.get(key);
    if (block === undefined) {
        block = { rendered: false, entries: [] as unknown as ImCacheEntries };
        map.set(key, block);
    }

    /**
     * You're rendering this list element twice. You may have duplicate keys in your dataset.
     * If that is not the case, a more common cause is that you are mutating collections while iterating them.
     * All sorts of bugs and performance issues tend to arise when I 'gracefully' handle this case, so I've just thrown an exception instead.
     *
     * If you're doing this in an infrequent event, here's a quick fix:
     * {
     *      let deferredAction: () => {} | undefined;
     *      imCacheListItem(s);
     *      for (item of list) {
     *          if (event) deferredAction = () => literally same mutation
     *      }
     *      imCacheListItemEnd(s);
     *      if (deferredAction) deferredAction();
     * }
     */
    assert(block.rendered === false);

    block.rendered = true;

    const parentType = entries[ENTRIES_PARENT_TYPE];
    const parent = entries[ENTRIES_PARENT_VALUE];

    imCacheEntriesBegin(c, block.entries, parentType, parent, INTERNAL_TYPE_KEYED_BLOCK);
}

/**
 * Allows you to reuse the same component for the same key.
 * This key is local to the current entry list, which means that multiple `imKeyedBegin` calls all reuse the same entry list
 * pushed by `imFor` in this example:
 *
 * ```ts
 * imFor(c); for (const val of list) {
 *      if (!val) continue;
 *      imKeyedBegin(c, val); { ... } imKeyedEnd(c);
 * } imForEnd(c);
 * ```
 */
export function imKeyedBegin(c: ImCache, key: ValidKey) {
    __imBlockKeyedBegin(c, key, REMOVE_LEVEL_DESTROYED);
}

export function imKeyedEnd(c: ImCache) {
    __imBlockDerivedEnd(c, INTERNAL_TYPE_KEYED_BLOCK);
}

// You probably don't need a destructor unless you're being forced to add/remove callbacks or 'clean up' something
export function cacheEntriesAddDestructor(c: ImCache, destructor: () => void) {
    const entries = c[CACHE_CURRENT_ENTRIES];
    let destructors = entries[ENTRIES_DESTRUCTORS];
    if (destructors === undefined) {
        destructors = [];
        entries[ENTRIES_DESTRUCTORS] = destructors;
    }

    destructors.push(destructor);
    c[CACHE_TOTAL_DESTRUCTORS]++;
}

function imCacheEntriesOnRemove(entries: ImCacheEntries) {
    recursivelyEnumerateEntries(entries, imCacheEntriesRemoveEnumerator);
}

export function recursivelyEnumerateEntries(entries: ImCacheEntries, fn: (entries: ImCacheEntries) => boolean) {
    const shouldEnumerate = fn(entries);
    if (shouldEnumerate) {
        for (let i = ENTRIES_ITEMS_START; i < entries.length; i += 2) {
            const t = entries[i];
            const v = entries[i + 1];
            if (t === imBlockBegin) {
                recursivelyEnumerateEntries(v, fn);
            }
        }


        let map = entries[ENTRIES_KEYED_MAP] as (Map<ValidKey, ListMapBlock> | undefined);
        if (map !== undefined) {
            for (const block of map.values()) {
                recursivelyEnumerateEntries(block.entries, fn);
            }
        }
    }
}

function imCacheEntriesRemoveEnumerator(entries: ImCacheEntries): boolean {
    // don't re-traverse these items.
    if (entries[ENTRIES_IS_IN_CONDITIONAL_PATHWAY] === true) {
        entries[ENTRIES_IS_IN_CONDITIONAL_PATHWAY] = false;
        return true;
    }

    return false;
}

function imCacheEntriesOnDestroy(c: ImCache, entries: ImCacheEntries) {
    // don't re-traverse these items.
    if (entries[ENTRIES_REMOVE_LEVEL] < REMOVE_LEVEL_DESTROYED) {
        entries[ENTRIES_REMOVE_LEVEL] = REMOVE_LEVEL_DESTROYED;

        for (let i = ENTRIES_ITEMS_START; i < entries.length; i += 2) {
            const t = entries[i];
            const v = entries[i + 1];
            if (t === imBlockBegin) {
                imCacheEntriesOnDestroy(c, v);
            }
        }

        const destructors = entries[ENTRIES_DESTRUCTORS];
        if (destructors !== undefined) {
            for (const d of destructors) {
                try {
                    d();
                    c[CACHE_TOTAL_DESTRUCTORS]--;
                } catch (e) {
                    console.error("A destructor threw an error: ", e);
                }
            }
            entries[ENTRIES_DESTRUCTORS] = undefined;
        }
    }
}

// This is the typeId for a list of cache entries.
export function imBlockBegin<T>(
    c: ImCache,
    parentTypeId: TypeId<T>,
    parent: T,
    internalType: number = INTERNAL_TYPE_NORMAL_BLOCK
): ImCacheEntries {
    let entries; entries = imGet(c, imBlockBegin);
    if (entries === undefined) {
        entries = imSet(c, [] as unknown as ImCacheEntries);
    }

    imCacheEntriesBegin(c, entries, parentTypeId, parent, internalType);

    return entries;
}

export function __GetEntries(c: ImCache): ImCacheEntries {
    const entries = c[CACHE_CURRENT_ENTRIES];
    return entries;
}

export function imBlockEnd(c: ImCache, internalType: number = INTERNAL_TYPE_NORMAL_BLOCK) {
    const entries = c[CACHE_CURRENT_ENTRIES];

    if (entries[ENTRIES_INTERNAL_TYPE] !== internalType) {
        const message = `Opening and closing blocks may not be lining up right. You may have missed or inserted some blocks by accident. `
            + "expected " + internalTypeToString(entries[ENTRIES_INTERNAL_TYPE]) + ", got " + internalTypeToString(internalType);
        throw new Error(message)
    }

    let map = entries[ENTRIES_KEYED_MAP] as (Map<ValidKey, ListMapBlock> | undefined);
    if (map !== undefined) {
        c[CACHE_TOTAL_MAP_ENTRIES] += map.size;

        const removeLevel = entries[ENTRIES_KEYED_MAP_REMOVE_LEVEL];
        if (removeLevel === REMOVE_LEVEL_DETATCHED) {
            for (const v of map.values()) {
                if (v.rendered === false) {
                    imCacheEntriesOnRemove(v.entries);
                }
            }
        } else if (removeLevel === REMOVE_LEVEL_DESTROYED) {
            // This is now the default for keyed elements. You will avoid memory leaks if they
            // get destroyed instead of detatched. 
            for (const [k, v] of map) {
                if (v.rendered === false) {
                    imCacheEntriesOnDestroy(c, v.entries);
                    map.delete(k);
                }
            }
        } else {
            throw new Error("Unknown remove level");
        }
    }

    entries[ENTRIES_COMPLETED_ONE_RENDER] = true;

    const idx = entries[ENTRIES_IDX];
    const lastIdx = entries[ENTRIES_LAST_IDX];
    if (idx !== lastIdx) {
        if (lastIdx === ENTRIES_ITEMS_START - 2) {
            // This was the first render. All g
            entries[ENTRIES_LAST_IDX] = idx;
        } else if (idx !== ENTRIES_ITEMS_START - 2) {
            // This was not the first render...
            c[CACHE_HMR_STATE_INCOMPATIBLE] = true;
            throw new Error("You should be rendering the same number of things in every render cycle");
        }
    }

    imCacheEntriesEnd(c);
}

export function __imBlockDerivedBegin(c: ImCache, internalType: number): ImCacheEntries {
    const entries = c[CACHE_CURRENT_ENTRIES];
    const parentType = entries[ENTRIES_PARENT_TYPE];
    const parent = entries[ENTRIES_PARENT_VALUE];

    return imBlockBegin(c, parentType, parent, internalType);
}

// Not quite the first render - 
// if the function errors out before the entries finish one render, 
// this method will rerender. Use this when you want to do something maybe once or twice or several times but hopefully just once,
// as it doesn't require an additional im-state entry. 
// For example, if you have an API like this:
// ```ts
// imDiv(c); imRow(c); imCode(c); imJustifyCenter(c); imBg(c, cssVars.bg); {
// } imDivEnd(c);
// ```
// Each of those methods that 'augment' the call to `imDiv` may have their own initialization logic.
export function isFirstishRender(c: ImCache): boolean {
    const entries = c[CACHE_CURRENT_ENTRIES];
    return entries[ENTRIES_COMPLETED_ONE_RENDER] === false;
}

export function __imBlockDerivedEnd(c: ImCache, internalType: number) {
    // The DOM appender will automatically update and diff the children if they've changed.
    // However we can't just do
    // ```
    // if (blah) {
    //      new component here
    // }
    // ```
    //
    // Because this would de-sync the immediate mode call-sites from their positions in the cache entries.
    // But simply putting them in another entry list:
    //
    // imConditionalBlock();
    // if (blah) {
    // }
    // imConditionalBlockEnd();
    //
    // Will automatically isolate the next immediate mode call-sites with zero further effort required,
    // because all the entries will go into a single array which always takes up just 1 slot in the entries list.
    // It's a bit confusing why there isn't more logic here though, I guess.
    //
    // NOTE: I've now moved this functionality into core. Your immediate mode tree builder will need
    // to resolve diffs in basically the same way.

    imBlockEnd(c, internalType);
}

/**
 * Usage:
 * ```ts
 *
 * // Annotating the control flow is needed - otherwise it won't work
 *
 * if (imIf(c) && <condition>) {
 *      // <condition> will by adequately type-narrowed by typescript
 * } else if (imElseIf(c) && <condition2>){
 *      // <condition>'s negative will not by adequately type-narrowed here though, sadly.
 *      // I might raise an issue on their github soon.
 * } else {
 *      imElse(c);
 *      // <condition>'s negative will not by adequately type-narrowed here though, sadly, same as above.
 * } imIfEnd(c);
 *
 * ```
 *
 * It effectively converts a variable number of im-entries into a single if-entry,
 * that has a fixed number of entries within it, so it still abides by 
 * the immediate mode restrictions.
 * This thing works by detecting if 0 things were rendered, and 
 * then detatching the things we rendered last time if that was the case. 
 * Even though code like below will work, you should never write it:
 * ```ts
 * // technically correct but dont do it like this:
 * imIf(c); if (<condition>) {
 * } else {
 *      imElse(c);
 * }imIfEnd(c);
 * ```
 * Because it suggests that you can extend it like the following, which would
 * no longer be correct:
 * ```ts
 * imIf(c); if (<condition>) {
 * } else if (<condition2>) {
 *      // NOO this will throw or corrupt data :((
 *      imElseIf(c);
 * } else {
 *      imElse(c);
 * } imIfEnd(c);
 * ```
 *
 * The framework assumes that every conditional annotation will get called in order,
 * till one of the conditions passes, after which the next annotation is `imIfEnd`. 
 * But now, it is no longer guaranteed that imElseIf will always be called if <condition> was false.
 * This means the framework has no way of telling the difference between the else-if block
 * and the else block (else blocks and else-if blocks are handled the same internally).
 */
export function imIf(c: ImCache): true {
    __imBlockArrayBegin(c);
    __imBlockConditionalBegin(c);
    return true;
}

export function imIfElse(c: ImCache): true {
    __imBlockConditionalEnd(c);
    __imBlockConditionalBegin(c);
    return true;
}

export function imIfEnd(c: ImCache) {
    __imBlockConditionalEnd(c);
    __imBlockArrayEnd(c);
}

// All roads lead to rome (TM) design pattern. not sure if good idea or shit idea
export const imEndIf = imIfEnd;
export const imElse = imIfElse;
export const imEndSwitch = imSwitchEnd;
export const imEndFor = imForEnd;
export const imCatch = imTryCatch;

/**
 * Example usage:
 * ```ts
 * imSwitch(c, key) switch (key) {
 *      case a: { ... } break;
 *      case b: { ... } break;
 *      case c: { ... } break;
 * } imSwitchEnd(c);
 * ```
 * ERROR: Don't use fallthrough, use if-else + imIf/imIfElse/imIfEnd instead. 
 * Fallthrough doesn't work as you would expect - for example:
 * ```ts
 *  imSwitch(c,key); switch(key) {
 *          case "A": { imComponent1(c); } // fallthrough (nooo)
 *          case "B": { imComponent2(c); }
 *  } imSwitchEnd(c);
 * ```
 * When the key is `b`, an instance of imComponent2 is rendered. However,
 * when the key is `a`, two completely separate instances of `imComponent1` and `imComponent2` are rendered.
 *      You would expect the `imComponent2` from both switch cases to be the same instance, but they are duplicates 
 *      with none of the same state.
 * 
 */
export function imSwitch(c: ImCache, key: ValidKey, cached: boolean = false) {
    __imBlockDerivedBegin(c, INTERNAL_TYPE_SWITCH_BLOCK);
    // I expect the keys to a switch statement to be constants that are known at 'compile time', 
    // so we don't need to worry about the usual memory leaks we would get with normal keyed blocks.
    // NOTE: However, switches can have massive components behind them.
    // This decision may be reverted in the future if we find it was a mistake.
    __imBlockKeyedBegin(c, key, cached ? REMOVE_LEVEL_DETATCHED : REMOVE_LEVEL_DESTROYED);
}

export function imSwitchEnd(c: ImCache) {
    __imBlockDerivedEnd(c, INTERNAL_TYPE_KEYED_BLOCK);
    __imBlockDerivedEnd(c, INTERNAL_TYPE_SWITCH_BLOCK);
}

function __imBlockArrayBegin(c: ImCache) {
    __imBlockDerivedBegin(c, INTERNAL_TYPE_ARRAY_BLOCK);
}

function __imBlockConditionalBegin(c: ImCache) {
    __imBlockDerivedBegin(c, INTERNAL_TYPE_CONDITIONAL_BLOCK);
}

function __imBlockConditionalEnd(c: ImCache) {
    const entries = c[CACHE_CURRENT_ENTRIES];
    if (entries[ENTRIES_IDX] === ENTRIES_ITEMS_START - 2) {
        // The index wasn't moved, so nothing was rendered.
        // This tells the conditional block to remove everything rendered under it last. 
        imCacheEntriesOnRemove(entries);
    }

    __imBlockDerivedEnd(c, INTERNAL_TYPE_CONDITIONAL_BLOCK);
}

export function imFor(c: ImCache) {
    __imBlockArrayBegin(c);
}

export function imForEnd(c: ImCache) {
    __imBlockArrayEnd(c);
}

function __imBlockArrayEnd(c: ImCache) {
    const entries = c[CACHE_CURRENT_ENTRIES]

    const idx = entries[ENTRIES_IDX];
    const lastIdx = entries[ENTRIES_LAST_IDX];
    if (idx < lastIdx) {
        // These entries have left the conditional rendering pathway
        for (let i = idx + 2; i <= lastIdx; i += 2) {
            const t = entries[i];
            const v = entries[i + 1];
            if (t === imBlockBegin) {
                imCacheEntriesOnRemove(v);
            }
        }
    }

    // we allow growing or shrinking this kind of block in particular
    entries[ENTRIES_LAST_IDX] = idx;

    __imBlockDerivedEnd(c, INTERNAL_TYPE_ARRAY_BLOCK);
}

// This is the initial value, so that anything, even `undefined`, can trigger imMemo
const IM_MEMO_FIRST_EVER = {};

export const MEMO_NOT_CHANGED = 0;
/** returned by {@link imMemo} if the value changed */
export const MEMO_CHANGED = 1;
/** 
 * returned by {@link imMemo} if this is simply the first render. 
 * Most of the time the distinction is not important, but sometimes,
 * you want to happen on a change but NOT the initial renderer.
 */
export const MEMO_FIRST_RENDER = 2;
/** 
 * returned by {@link imMemo} if this is is caused by the component
 * re-entering the conditional rendering codepath.
 */
export const MEMO_FIRST_RENDER_CONDITIONAL = 3;

export type ImMemoResult
    = typeof MEMO_NOT_CHANGED
    | typeof MEMO_FIRST_RENDER
    | typeof MEMO_CHANGED
    | typeof MEMO_FIRST_RENDER_CONDITIONAL;

/**
 * Returns non-zero when either:
 *  1. val was different from the last value, 
 *  2. the component wasn't in the conditional rendering pathway before,
 *    but it is now
 *
 * 1 makes sense, but 2 only arises is because we want code like this to work
 * in any concievable context:
 *
 * ```ts
 * function uiComponent(focused: boolean) {
 *      if (imMemo(c, focused)) {
 *          // recompute state
 *      }
 * }
 * ```
 *
 * With 1. alone, it won't work if the component leaves the conditional rendering pathway, 
 * and then re-enters it:
 *
 * ```ts
 * imSwitch(c); switch(currentComponent) {
 *      case "component 1": uiComponent(true); break;
 *      case "component 2": somethingElse(true); break;
 *  } imSwitchEnd(c);
 * ```
 *
 * But with 2. as well, it should always work as expected.
 *
 * NOTE: NaN !== NaN. So your memo will fire every frame. 
 * I'm still diliberating on should my code be 'correct' and always handle this for every imMemo, 
 * even when it doesn't really need to, or if you sohuld just handle it as needed. 
 * For now, you can handle it.
 *
 * NOTE: you can use the bitwise-or operator if you just want to check if multiple values have changed
 * without extracing value1Changed, value2Changed, etc. variables since this is not short-circuiting like the || operator.
 * 
 * ```ts
 * if (imMemo(c, value1) | imMemo(c, value2) | imMemo(c, value3) | imMemo(c, value4)) {
 *      // Something
 * }
 * ```
 */
export function imMemo(c: ImCache, val: unknown): ImMemoResult {
    /**
     * NOTE: I had previously implemented imMemo() and imMemoEnd():
     *
     * ```ts
     * if (imMemoBegin().val(x).objectVals(obj)) {
     *      <Memoized component>
     * } imMemoEnd();
     * ```
     * It can be done, but I've found that it's a terrible idea in practice.
     * I had initially thought {@link imMemo} was bad too, but it has turned out to be very useful.
     * turned out to be very useful, more so even, than imMemo2(c, ...manyArgs)
     */

    let result: ImMemoResult = MEMO_NOT_CHANGED;

    const entries = c[CACHE_CURRENT_ENTRIES];

    let lastVal = imGet(c, inlineTypeId(imMemo), IM_MEMO_FIRST_EVER);
    if (lastVal !== val) {
        imSet(c, val);
        if (lastVal === IM_MEMO_FIRST_EVER) {
            result = MEMO_FIRST_RENDER;
        } else {
            result = MEMO_CHANGED;
        }
    } else if (entries[ENTRIES_STARTED_CONDITIONALLY_RENDERING] === true) {
        result = MEMO_FIRST_RENDER_CONDITIONAL;
    }

    return result;
}

export type TryState = {
    entries: ImCacheEntries;
    err: any | null;
    recover: () => void;
    unwoundThisFrame: boolean;
    // TODO: consider Map<Error, count: number>
};

/**
 * ```ts
 * const tryState = imTry(c); try {
 *      // render your component here
 * } catch(err) {
 *      imTryCatch(c, tryState, err);
 *      // don't render anything here! Only do the other things
 * } imTryEnd(c, tryState); 
 * ```
 */
export function imTry(c: ImCache): TryState {
    const entries = __imBlockDerivedBegin(c, INTERNAL_TYPE_TRY_BLOCK);

    let tryState = imGet(c, imTry);
    if (tryState === undefined) {
        const val: TryState = {
            err: null,
            recover: () => {
                val.err = null;
                c[CACHE_NEEDS_RERENDER] = true;
            },
            entries,
            unwoundThisFrame: false,
        };
        tryState = imSet(c, val);
    }

    tryState.unwoundThisFrame = false;

    return tryState;
}

export function imTryCatch(c: ImCache, tryState: TryState, err: any) {
    tryState.unwoundThisFrame = true;

    if (tryState.err != null) {
        throw new Error("Your error boundary pathway also has an error in it, so we can't recover!");
    }

    c[CACHE_NEEDS_RERENDER] = true;
    tryState.err = err;
    const idx = c.lastIndexOf(tryState.entries);
    if (idx === -1) {
        throw new Error("Couldn't find the entries in the stack to unwind to!");
    }

    c[CACHE_IDX] = idx - 1;
    c[CACHE_CURRENT_ENTRIES] = c[idx - 1];
}

export function imTryEnd(c: ImCache, tryState: TryState) {
    if (tryState.unwoundThisFrame === true) {
        // nothing to end.
        assert(c[c[CACHE_IDX] + 1] === tryState.entries);
    } else {
        const entries = c[CACHE_CURRENT_ENTRIES];
        assert(entries === tryState.entries);
        __imBlockDerivedEnd(c, INTERNAL_TYPE_TRY_BLOCK);
    }
}

export function getDeltaTimeSeconds(c: ImCache): number {
    return c[CACHE_ANIMATION_DELTA_TIME_SECONDS];
}

// Events can trigger rerenders in the same frame.
export function getRenderCount(c: ImCache) {
    return c[CACHE_RENDER_COUNT];
}

/**
 * Sometimes, you'll need a global state stack, so that you have access to some state.
 * ```ts
 *
 * globalStateStackPush(gssThing, thing); {
 *      ...
 *      // can be arbitrarily deep inside the component
 *      const thing = globalStateStackGet(gssThing);
 *
 *      ...
 * } globalStateStackPop(gssThing);
 * ```ts
 *
 * 99% of the time, this pattern is a mistake that obfuscates and overcomplicates the code, 
 * and you should just pass `thing` as an additional function parameter.
 * And for things you pass around *a lot* like c: ImCache, you will incur a significant performance
 * hit by using this approach (as of 08/2025) (on top of the perf hit of using this framework).
 *
 * Here is a decision matrix you can use to decide whether to use this pattern or not:
 *
 *                                      | I need this state everywhere,    | I infrequently need this value, but the requirement can arise 
 *                                      | and I make sure to pass it as    | naturally somewhere deep node of the component, and I have
 *                                      | a method param everywhere anyway | to spend a bunch of time adding an extra function argument 
 *                                      |                                  | everywhere when it does.
 * ----------------------------------------------------------------------------------------------------------------------------
 *  This state is related to my app's   | Don't use a global state stack   | Don't use a global state stack 
 *  domain model                        | ctx: AppGlobalState is here      | s: BlahViewState is here
 * ----------------------------------------------------------------------------------------------------------------------------
 *  This state is not related to my     | Don't use a global state stack   | Consider using a global state stack
 *  app's domain model                  | c: ImCache is here               | getGlobalEventSystem() is here
 * ----------------------------------------------------------------------------------------------------------------------------
 *
 */
export function globalStateStackPush<T>(gss: T[], item: T) {
    // I've put a limit on the context depth to 100. But really, anything > 1 is already a niche usecase, and anything > 2 may never happen in practice ... 
    if (gss.length > 100) {
        throw new Error("Looks like you're forgetting to pop items from your global state array. tsk tsk tsk. ");
    }

    gss.push(item);
}

export function globalStateStackGet<T>(gss: T[]): T {
    // No context item was pushed
    assert(gss.length > 0);

    return gss[gss.length - 1];
}

export function globalStateStackPop<T>(gss: T[], item: T): T {
    const currentItem = globalStateStackGet(gss);

    // Item may have changed mid-render, which definitely shouldn't ever happen, and is indicative of some other issue.
    assert(currentItem === item);

    gss.pop();

    return currentItem;
}


// Basically, HMR works like this. At least, for Vite it definitely does.
//
// [module 1] --needs hot-reload-> accept([module 2])
// [module 2] --needs hot-reload-> accept([module 3])
// [module 3] --needs hot-reload-> accept([module 4])
// ....
//
// each older module needs to accept the new module. This only happens once per-module.
// The module needs to pass along the very first module in the chain for state retention 
// to work. I anticipate a similar API for other bundlers.
export type HmrState = {
    imMain: (c: ImCache) => void;
    cGlobal: ImCache;
    timeout: number;
    accept: (newModule: any, onInvalidate: (() => void) | undefined) => void;
};


/**
 * HMR core function. See {@link HmrState} for an explanation of HMR.
 * Here is how you would use it with Vite (IS_PROD env variable not included):
 * ```ts
 * export let hmr: HmrState | undefined;
 * 
 * if (IS_PROD) {
 *     imMain([]);
 * } else {
 *     hmr = startRenderingWithHMR(imMain);
 *     if (import.meta.hot) {
 *         import.meta.hot.accept((newModule) => {
 *             hmr!.accept(newModule, import.meta.hot?.invalidate);
 *         });
 *     }
 * }
 * ```
 * Other bundlers will require slightly differnt code. 
 * You could put your own invalidator that does fancier logic.
 *
 * NOTE: doing HMR properly can significantly increase the complexity of your app, for very little cost. 
 * Don't reach for this till making tiny changes to styling or whatever is really slow.
 */
export function startRenderingWithHMR(
    renderFn: (c: ImCache) => void,
    cGlobal: ImCache = [],
): HmrState {
    // The previous module has this long to prevent the next module from initializing a
    // fresh copy of itself.
    const HMR_TIMEOUT = 100;
    const timeout = setTimeout(() => {
        console.log("[hmr] the first state has been initialized");
        renderFn(cGlobal);
    }, HMR_TIMEOUT);

    const hmr: HmrState = {
        imMain: renderFn,
        cGlobal: cGlobal,
        timeout: timeout,
        accept: (newModule, onInvalidate) => {
            if (!newModule) return;
            const newHmr = newModule.hmr;
            if (!newHmr) {
                console.warn("[hmr] The new module did not export the previous HMR state in a variable called 'hmr', invalidating...");
                onInvalidate?.();
                return;
            }

            // But it works though
            const HMR_HACK_TIMEOUT = 30;
            setTimeout(() => {
                let err;
                try {
                    // Stop new module entrypoint, and pass our state forwards
                    clearTimeout(newHmr.timeout);
                    newHmr.cGlobal = hmr.cGlobal;

                    console.log("[hmr] Attempting to patch the new render function...");
                    hmr.cGlobal[CACHE_HMR_ENABLED] = true;
                    newModule.hmr.imMain(hmr.cGlobal);
                } catch (e) {
                    err = e;
                }

                // NOTE: CACHE_HMR_ENABLED is now a flag that gets set to true once, and stays that way.
                // I had wanted it to be a gate that I turn on and then turn off here, but that won't work - 
                // a `requestAnimationFrame` invoked 2 frames later will throw errors R.E patching
                // of typeIds, which is somewhat unexpected.
                // If I debug with breakpoints however, it does work as expected. This indicates that
                // the functions must get asyncronously patched some time after HMR actually
                // runs this accept callback. For now, I have noticed that I can also get it to work
                // as expected when I use HMR_HACK_TIMEOUT - it must have a similar effect to putting
                // in a breakpoint.

                let invalidate = false;
                if (err) {
                    console.log("[hmr] Couldn't hot-reload: ", err);
                    invalidate = true;
                } else if (hmr.cGlobal[CACHE_HMR_STATE_INCOMPATIBLE]) {
                    console.log("[hmr] Couldn't hot-reload - the new component state layout is no longer compatible with the previous state");
                    invalidate = true;
                }

                if (invalidate) {
                    imCacheStopImmediately(hmr.cGlobal);
                    try {
                        onInvalidate?.();
                    } catch (e) {
                        console.error("[hmr] failed to invalidate: ", e);
                        window.location.reload();
                    }
                } else {
                    console.log("[hmr] Reloaded x" + hmr.cGlobal[CACHE_RENDER_FN_CHANGES]);
                }

            }, HMR_HACK_TIMEOUT);
        }
    };

    return hmr;
}

